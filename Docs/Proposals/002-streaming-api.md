# Streaming LLM API

- Proposal: [SAI-002](https://github.com/mi12labs/SwiftAI/blob/main/Docs/Proposals/002-streaming-llm-api.md)
- Depends on: [SAI-001](https://github.com/mi12labs/SwiftAI/blob/main/Docs/Proposals/001-llm-api.md) (LLM API)

## Introduction

The current SwiftAI LLM API provides a `reply(to:)` that returns complete responses. However, language models often take several seconds to generate responses.

This proposal extends the LLM protocol with streaming capabilities, enabling real-time response generation and progressive rendering of structured output.

## Proposed solution

This proposal adds a streaming API to the existing LLM protocol. The streaming API mirrors the structure of the existing `reply(to:)` API while returning `AsyncStream` instead of direct results.

### Core Streaming API

```swift
protocol LLM {
  // Existing synchronous methods remain unchanged
  func reply<T: Generable>(...) async throws -> LLMReply<T>

  // New streaming methods
  func replyStream<T: Generable>(
    to messages: [Message],
    returning type: T.Type,
    tools: [any Tool],
    options: LLMReplyOptions
  ) -> AsyncThrowingStream<T.Partial, Error> where T: Sendable

  func replyStream<T: Generable>(
    to prompt: Prompt,
    returning type: T.Type,
    in session: Session,
    options: LLMReplyOptions
  ) -> AsyncThrowingStream<T.Partial, Error> where T: Sendable
}
```

### Partial Type Support

The `Generable` protocol includes a `Partial` associatedtype for streaming support:

```swift
public protocol Generable: Codable, Sendable {
  /// The partial type used for streaming responses.
  associatedtype Partial: Codable, Sendable

  // ... other requirements
}
```

For basic types, `Partial` defaults to `Self`:

```swift
extension String: Generable {
  Partial = Self
}

extension Int: Generable {
  Partial = Self
}
```

For complex structs, the `@Generable` macro can generate appropriate partial types:

```swift
@Generable
struct ResearchPaper {
  let title: String
  let authors: [String]
  let abstract: String
  let keywords: [String]
  let contact: ContactInfo
}

// Future: Generated by @Generable macro
extension ResearchPaper {
  struct Partial: Codable, Sendable {
    var title: String.Partial?
    var authors: [String].Partial?
    var abstract: String.Partial?
    var keywords: [String].Partial?
    var contact: ContactInfo.Partial?
  }
}
```

### Streaming Behavior

The streaming API emits progressive updates as the LLM generates content:

1. **Text fields**: Emitted progressively
1. **Bools / Numbers / Enums**: Emit when complete
1. **Nested objects**: Use recursive partial types
1. **Arrays**: Start as `nil`, then grow incrementally. Individual elements recursively follow the streaming rules above.

### Tool Integration

Tools work identically to the `reply(to:)` API. The LLM pauses streaming to call tools, then resumes with the tool results incorporated.
Tool calls are NOT streamed.

### Session Management

Session-based streaming follows the same patterns as `reply(to:)` sessions:

```swift
let session = llm.makeSession {
  "You are a research assistant specializing in climate science."
}

let stream = llm.replyStream(
  to: "Summarize the latest IPCC findings",
  returning: ClimateReport.self,
  in: session
)

for try await partial in stream {
  // Process incremental updates
  updateUI(with: partial)
}
```

The state of the session is updated after each message is streamed in full.

### Generated Partial Types

The `@Generable` macro generates partial types with these characteristics:

- **All fields are optional**: Enables incremental population
- **Codable conformance**: Supports serialization from JSON
- **Sendable conformance**: Thread-safe for concurrent access
- **Recursive partials**: Nested `@Generable` types get their own partial variants

## Usage Examples

### Basic Streaming

```swift
let stream = llm.replyStream(
  to: "Write a product review",
  returning: ProductReview.self
)

for try await partial in stream {
  if let rating = partial.rating {
    updateStarRating(rating)
  }
  if let title = partial.title {
    updateTitle(title)
  }
  if let content = partial.content {
    updateContent(content)
  }
}
```

## Alternatives considered

- **Event-based streaming**: Stream events which include chunks, snapshots, markers, and tools calls. We may support this later.
